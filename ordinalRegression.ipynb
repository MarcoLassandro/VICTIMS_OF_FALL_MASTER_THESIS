{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c17a740-0bef-4d34-a8eb-38cdc67de62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_1 = 7\n",
    "cpu_2 = 7\n",
    "@Cache(\n",
    "    cache_path=\"results/{experiment_name}.json\"\n",
    ")\n",
    "def experiment(path, experiment_name, experiment_setup):\n",
    "    all_performance = []\n",
    "    for dataset in dataset_list:\n",
    "        dataset_variant = dataset[\"dataset_variant\"]\n",
    "        print(dataset_variant)\n",
    "\n",
    "        X = dataset[\"X\"].to_numpy()\n",
    "        y = dataset[\"y\"].to_numpy(dtype = 'int32').ravel()\n",
    "\n",
    "        #TYPE OF TASK\n",
    "        task = experiment_setup['task']\n",
    "        \n",
    "        #THE MASK IS REQUIRED WHEN MASKEDPCA OR MASKEDSVD IS USED\n",
    "        if experiment_setup[\"dataset_settings\"][\"only_BMI\"] == 1:\n",
    "            mask = np.arange(X.shape[1]) > 2\n",
    "        else:\n",
    "            mask = np.arange(X.shape[1]) > 4\n",
    "\n",
    "        #BUILDING THE PIPELINE\n",
    "        pipe_steps = []\n",
    "        for key, value in experiment_setup[\"pipe\"].items():\n",
    "            pipe_steps.append((key, eval(value)))\n",
    "        pipe = Pipeline(pipe_steps)    \n",
    "        \n",
    "        hp_optimizer = experiment_setup[\"hp_optimizer\"]\n",
    "        metrics = hp_optimizer.get(\"metrics\")\n",
    "        \n",
    "        params_list = []\n",
    "        parsed_params = {}\n",
    "        for parameter, values in hp_optimizer.get(\"params\")[0].items():\n",
    "            parsed_params[parameter] = eval(values)\n",
    "        params_list.append(parsed_params)\n",
    "            \n",
    "        list_skf = []\n",
    "                \n",
    "        if \"n_split_outer_cv\" in hp_optimizer.keys():\n",
    "            cv_type = \"n_split_outer_cv\"\n",
    "            list_skf.append(StratifiedKFold(n_splits=hp_optimizer[cv_type], shuffle = True, random_state=42))\n",
    "        \n",
    "        if \"n_split_inner_cv\" in hp_optimizer.keys():\n",
    "            cv_type = \"n_split_inner_cv\"\n",
    "            list_skf.append(StratifiedKFold(n_splits=hp_optimizer[cv_type], shuffle = True, random_state=42))\n",
    "            \n",
    "        if hp_optimizer[\"type\"] == 'GridSearchCV':\n",
    "            optimizer = GridSearchCV(pipe, parsed_params, n_jobs = cpu_1, cv=list_skf[-1], verbose=1, scoring = metrics, refit = metrics[0], return_train_score=True).fit(X,y)\n",
    "        elif hp_optimizer[\"type\"] == 'RandomizeSearchCV':\n",
    "            n_iter = hp_optimizer[\"n_iter\"] if \"n_iter\" in hp_optimizer.keys() else 100\n",
    "            print(f\"n_iter:{n_iter}\")\n",
    "            optimizer = RandomizedSearchCV(pipe, parsed_params, n_iter = n_iter, cv=list_skf[-1], verbose=1, scoring = metrics, refit = metrics[0], return_train_score=True).fit(X,y)\n",
    "        elif hp_optimizer[\"type\"] == 'BayesSearchCV':\n",
    "            n_iter = hp_optimizer[\"n_iter\"] if \"n_iter\" in hp_optimizer.keys() else 100\n",
    "            print(f\"n_iter:{n_iter}\")  \n",
    "            optimizer = BayesSearchCV(pipe, parsed_params, n_jobs = cpu_1, n_iter = n_iter, cv=list_skf[-1], verbose=1, scoring = metrics, refit = metrics[0], return_train_score=True).fit(X,y)\n",
    "\n",
    "        if \"n_split_inner_cv\" in hp_optimizer.keys():\n",
    "            cv_dic = cross_validate(optimizer, X, y, cv=list_skf[0], scoring=metrics, return_estimator=True, verbose = 2, return_train_score=True)\n",
    "            best_params_cv = [estimator.best_params_ for estimator in cv_dic[\"estimator\"]]\n",
    "            \n",
    "            scores_test_dict = {}\n",
    "            scores_train_dict = {}\n",
    "            for metric in metrics:\n",
    "                scores_test_dict[metric] = np.mean(cv_dic[f\"test_{metric}\"])\n",
    "                scores_train_dict[metric] = np.mean(cv_dic[f\"train_{metric}\"])\n",
    "\n",
    "            cv_results = str(cv_dic)\n",
    "        else:\n",
    "            best_params_cv = [optimizer.best_params_]\n",
    "            best_model = pd.DataFrame(optimizer.cv_results_).iloc[optimizer.best_index_]\n",
    "\n",
    "            scores_test_dict = {}\n",
    "            scores_train_dict = {}\n",
    "            for metric in metrics:\n",
    "                scores_test_dict[metric] = best_model[f\"mean_test_{metric}\"]\n",
    "                scores_train_dict[metric] = best_model[f\"mean_train_{metric}\"]\n",
    "\n",
    "            cv_results = str(optimizer.cv_results_)\n",
    "            \n",
    "        score = {\n",
    "            \"experiment_name\": experiment_name,\n",
    "            \"dataset_variant\": dataset_variant,\n",
    "            \"estimator\" : experiment_setup['pipe']['estimator'],\n",
    "            \"task\": task,\n",
    "            \"hp_optimizer\": hp_optimizer['type'],\n",
    "            \"cv_type\": cv_type,\n",
    "            \"mean_test_score\": scores_test_dict,\n",
    "            \"mean_train_score\": scores_train_dict,\n",
    "            \"best_params\": str(best_params_cv),\n",
    "            \"cv_results\" : cv_results,\n",
    "            \"experiment_setup\": experiment_setup\n",
    "        }\n",
    "        \n",
    "        all_performance.append(score)\n",
    "                \n",
    "    return all_performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
