{
    "creation_time": 1637150156.7187328,
    "creation_time_human": "2021-11-17 12:55:56",
    "time_delta": 338.94269156455994,
    "time_delta_human": "5 minutes and 38 seconds",
    "file_dump_time": 0.0019998550415039062,
    "file_dump_time_human": "0 seconds",
    "file_dump_size": 47698,
    "file_dump_size_human": "47.7 kB",
    "load_kwargs": {},
    "dump_kwargs": {},
    "function_name": "experiment",
    "function_file": "C:\\Users\\NileNile\\AppData\\Local\\Temp/ipykernel_8672/3862192823.py:67",
    "args_to_ignore": [],
    "source": "@Cache(\n    cache_path=\"results/{experiment_name}.json\"\n)\ndef experiment(path, experiment_name, experiment_setup):\n    path_str = \"data/victims_of_fall_V1.csv\"\n    df = pd.read_csv(path_str)\n    binarize = None if \"binarize\" not in experiment_setup.keys() else eval(experiment_setup[\"binarize\"])\n        \n    dataset_list = get_dataset(df, experiment_setup[\"dataset_variants\"], eval(experiment_setup[\"only_BMI\"]), eval(experiment_setup[\"floor_labels\"]), binarize)\n\n    all_performance = []\n    for dataset in dataset_list:\n        dataset_variant = dataset[\"dataset_variant\"]\n        print(dataset_variant)\n\n        X = dataset[\"X\"].to_numpy()\n        y = dataset[\"y\"].to_numpy().ravel()\n\n        if eval(experiment_setup[\"use_special_mask\"]) == True and dataset_variant == \"complete\":\n            mask = [0,0,0,0,0,0,1,1,1,1,1,0,2,2,2,2,2,0,3,3,3,3,3,0,4,4,4,4,4]\n        else:\n            if eval(experiment_setup[\"only_BMI\"]) == True:\n                mask = np.arange(X.shape[1]) > 2\n            else:\n                mask = np.arange(X.shape[1]) > 4\n\n        pipe_steps = []\n        if \"reduce_dim\" in experiment_setup.keys():\n            reduce_dim = eval(experiment_setup[\"reduce_dim\"])\n            pipe_steps.append((\"reduce_dim\", reduce_dim[0]))\n\n        if \"scaler\" in experiment_setup.keys():\n            scaler = eval(experiment_setup[\"scaler\"])\n            pipe_steps.append((\"scaler\", scaler[0]))\n            \n        if \"refit_metric\" in experiment_setup.keys():\n            refit_metric =  experiment_setup[\"refit_metric\"]\n        else:\n            refit_metric =  True\n            \n        print(refit_metric)\n\n        if \"regressor\" in experiment_setup.keys():\n            estimator = eval(experiment_setup[\"regressor\"])\n            pipe_steps.append((\"regressor\", estimator[0]))\n        elif \"clf\" in experiment_setup.keys():\n            estimator = eval(experiment_setup[\"clf\"])\n            pipe_steps.append((\"clf\", estimator[0]))\n\n        if  \"params\" in experiment_setup.keys():\n            params = experiment_setup[\"params\"]\n\n        if \"n_split_inner_kcv\" in experiment_setup.keys():\n            inner_skf = StratifiedKFold(n_splits=experiment_setup[\"n_split_inner_kcv\"], shuffle = True, random_state=42)\n\n        if \"n_split_outer_kcv\" in experiment_setup.keys():\n            outer_skf = StratifiedKFold(n_splits=experiment_setup[\"n_split_outer_kcv\"], shuffle = True, random_state=42)\n\n        parsed_params = eval_params(params, X, mask)\n        metrics = eval(experiment_setup[\"metrics\"])\n\n        pipe = Pipeline(pipe_steps)\n\n        if \"n_split_inner_kcv\" in experiment_setup.keys():\n            if \"hp_optimizer\" not in experiment_setup.keys():\n                hp_search = GridSearchCV(pipe, parsed_params, cv=inner_skf, verbose=1, scoring = metrics, refit = refit_metric, return_train_score=True).fit(X,y)\n            else:\n                hp_search = RandomizedSearchCV(pipe, parsed_params, n_iter = 100, cv=inner_skf, verbose=1, scoring = metrics, refit = refit_metric, return_train_score=True).fit(X,y)\n\n            cv_dic = cross_validate(hp_search, X, y, cv=outer_skf, scoring=metrics, return_estimator=True, return_train_score=True)\n            best_params_cv = [estimator.best_params_ for estimator in cv_dic[\"estimator\"]]\n            print(cv_dic)\n            \n            score = {\n                \"dataset_variant\": dataset_variant,\n                \"experiment_setup\": experiment_setup,\n                \"best_params\": str(best_params_cv),\n                \"mean_test_score\": [np.mean(cv_dic[f\"test_{metric}\"]) for metric in metrics],\n                \"mean_train_score\": [np.mean(cv_dic[f\"train_{metric}\"]) for metric in metrics],\n                \"cv_results\" : str(cv_dic)\n            }\n            \n        else:\n            if \"hp_optimizer\" not in experiment_setup.keys():\n                hp_search = GridSearchCV(pipe, parsed_params, cv=outer_skf, verbose=1, n_jobs = cpu_count(), scoring = metrics[0], return_train_score=True).fit(X,y)\n            else:\n                hp_search = RandomizedSearchCV(pipe, parsed_params, n_iter = 100, n_jobs = cpu_count(), cv=outer_skf, verbose=1, scoring = metrics[0], return_train_score=True).fit(X,y)\n\n            best_params_cv = hp_search.best_params_\n\n            score = {\n                \"dataset_variant\": dataset_variant,\n                \"experiment_setup\": experiment_setup,\n                \"best_params\": str(best_params_cv),\n                \"mean_test_score\": hp_search.best_score_,\n                \"cv_results\" : str(hp_search.cv_results_)\n            }\n\n        all_performance.append(score)\n                \n    return all_performance\n",
    "backend_metadata": {},
    "parameters": {
        "path": "./results/",
        "experiment_name": "Experiment_17_11_21",
        "experiment_setup": {
            "dataset_variants": [
                "complete",
                "only_binary",
                "only_totals"
            ],
            "only_BMI": "True",
            "use_special_mask": "False",
            "reduce_dim": "[MaskedPCA(mask=mask), MaskedSVD(mask=mask)]",
            "scaler": "[MinMaxScaler(), StandardScaler(), RobustScaler()]",
            "clf": "[FuzzyCMeans(n_centers = 7)]",
            "floor_labels": "True",
            "params": [
                {
                    "reduce_dim": "[MaskedPCA(mask=mask), MaskedSVD(mask=mask)]",
                    "reduce_dim__n_components": "np.arange(1, X[:, mask].shape[1])",
                    "scaler": "[MinMaxScaler()]"
                }
            ],
            "metrics": "['accuracy', 'neg_mean_absolute_error']",
            "refit_metric": "neg_mean_absolute_error",
            "n_split_outer_kcv": 10,
            "n_split_inner_kcv": 10
        }
    }
}