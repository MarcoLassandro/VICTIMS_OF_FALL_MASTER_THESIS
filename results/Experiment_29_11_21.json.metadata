{
    "creation_time": 1638206835.4480283,
    "creation_time_human": "2021-11-29 18:27:15",
    "time_delta": 893.6636548042297,
    "time_delta_human": "14 minutes and 53 seconds",
    "file_dump_time": 0.003987312316894531,
    "file_dump_time_human": "0 seconds",
    "file_dump_size": 59984,
    "file_dump_size_human": "60.0 kB",
    "load_kwargs": {},
    "dump_kwargs": {},
    "function_name": "experiment",
    "function_file": "C:\\Users\\NileNile\\AppData\\Local\\Temp/ipykernel_6068/2725657360.py:3",
    "args_to_ignore": [],
    "source": "@Cache(\n    cache_path=\"results/{experiment_name}.json\"\n)\ndef experiment(path, experiment_name, experiment_setup):\n    path_str = \"data/victims_of_fall_V1.csv\"\n    df = pd.read_csv(path_str)\n    binarize = None if \"binarize\" not in experiment_setup.keys() else eval(experiment_setup[\"binarize\"])\n        \n    dataset_list = get_dataset(df, experiment_setup[\"dataset_settings\"])\n\n    all_performance = []\n    for dataset in dataset_list:\n        dataset_variant = dataset[\"dataset_variant\"]\n        print(dataset_variant)\n\n        X = dataset[\"X\"].to_numpy()\n        y = dataset[\"y\"].to_numpy(dtype = 'int32').ravel()\n\n        #TYPE OF TASK\n        task = experiment_setup['task']\n        \n        #THE MASK IS REQUIRED WHEN MASKEDPCA OR MASKEDSVD IS USED\n        if experiment_setup[\"dataset_settings\"][\"only_BMI\"] == 1:\n            mask = np.arange(X.shape[1]) > 2\n        else:\n            mask = np.arange(X.shape[1]) > 4\n\n        #BUILDING THE PIPELINE\n        pipe_steps = []\n        for key, value in experiment_setup[\"pipe\"].items():\n            pipe_steps.append((key, eval(value)))\n        pipe = Pipeline(pipe_steps)    \n        \n        hp_optimizer = experiment_setup[\"hp_optimizer\"]\n        metrics = hp_optimizer.get(\"metrics\")\n        \n        params_list = []\n        parsed_params = {}\n        for parameter, values in hp_optimizer.get(\"params\")[0].items():\n            parsed_params[parameter] = eval(values)\n        params_list.append(parsed_params)\n            \n        list_skf = []\n                \n        if \"n_split_outer_cv\" in hp_optimizer.keys():\n            cv_type = \"n_split_outer_cv\"\n            list_skf.append(StratifiedKFold(n_splits=hp_optimizer[cv_type], shuffle = True, random_state=42))\n        \n        if \"n_split_inner_cv\" in hp_optimizer.keys():\n            cv_type = \"n_split_inner_cv\"\n            list_skf.append(StratifiedKFold(n_splits=hp_optimizer[cv_type], shuffle = True, random_state=42))\n            \n        if hp_optimizer[\"type\"] == 'GridSearchCV':\n            optimizer = GridSearchCV(pipe, parsed_params, n_jobs = cpu_1, cv=list_skf[-1], verbose=1, scoring = metrics, refit = metrics[0], return_train_score=True).fit(X,y)\n        elif hp_optimizer[\"type\"] == 'RandomizeSearchCV':\n            n_iter = hp_optimizer[\"n_iter\"] if \"n_iter\" in hp_optimizer.keys() else 100\n            print(f\"n_iter:{n_iter}\")\n            optimizer = RandomizedSearchCV(pipe, parsed_params, n_jobs = cpu_1, n_iter = n_iter, cv=list_skf[0], verbose=1, scoring = metrics, refit = metrics[0], return_train_score=True).fit(X,y)\n        elif hp_optimizer[\"type\"] == 'BayesSearchCV':\n            n_iter = hp_optimizer[\"n_iter\"] if \"n_iter\" in hp_optimizer.keys() else 100\n            print(f\"n_iter:{n_iter}\")  \n            optimizer = BayesSearchCV(pipe, parsed_params, n_jobs = cpu_1, n_iter = n_iter, cv=list_skf[0], verbose=1, scoring = metrics, refit = metrics[0], return_train_score=True).fit(X,y)\n\n        if \"n_split_inner_cv\" in hp_optimizer.keys():\n            cv_dic = cross_validate(optimizer, X, y, cv=list_skf[0], scoring=metrics, n_jobs = cpu_2, return_estimator=True, verbose = 2, return_train_score=True)\n            best_params_cv = [estimator.best_params_ for estimator in cv_dic[\"estimator\"]]\n            \n            scores_test_dict = {}\n            scores_train_dict = {}\n            for metric in metrics:\n                scores_test_dict[metric] = np.mean(cv_dic[f\"test_{metric}\"])\n                scores_train_dict[metric] = np.mean(cv_dic[f\"train_{metric}\"])\n\n            cv_results = str(cv_dic)\n        else:\n            best_params_cv = [optimizer.best_params_]\n            best_model = pd.DataFrame(optimizer.cv_results_).iloc[optimizer.best_index_]\n\n            scores_test_dict = {}\n            scores_train_dict = {}\n            for metric in metrics:\n                scores_test_dict[metric] = best_model[f\"mean_test_{metric}\"]\n                scores_train_dict[metric] = best_model[f\"mean_train_{metric}\"]\n\n            cv_results = str(optimizer.cv_results_)\n            \n        score = {\n            \"experiment_name\": experiment_name,\n            \"dataset_variant\": dataset_variant,\n            \"estimator\" : experiment_setup['pipe']['estimator'],\n            \"task\": task,\n            \"hp_optimizer\": hp_optimizer['type'],\n            \"cv_type\": cv_type,\n            \"mean_test_score\": scores_test_dict,\n            \"mean_train_score\": scores_train_dict,\n            \"best_params\": str(best_params_cv),\n            \"cv_results\" : str(cv_results),\n            \"experiment_setup\": experiment_setup\n        }\n        \n        all_performance.append(score)\n                \n    return all_performance\n",
    "backend_metadata": {},
    "parameters": {
        "path": "./results/",
        "experiment_name": "Experiment_29_11_21",
        "experiment_setup": {
            "dataset_settings": {
                "dataset_variants": [
                    "complete",
                    "only_totals",
                    "only_binary"
                ],
                "type_of_labels": "floors",
                "only_BMI": 1,
                "percentage": 1
            },
            "task": "Regression",
            "pipe": {
                "feature_extraction": "MaskedSVD(mask=mask)",
                "scaler": "MinMaxScaler()",
                "estimator": "RandomForestRegressor(criterion = 'squared_error')"
            },
            "hp_optimizer": {
                "type": "RandomizeSearchCV",
                "n_iter": 20,
                "params": [
                    {
                        "feature_extraction": "[MaskedSVD(mask=mask), MaskedPCA(mask=mask)]",
                        "feature_extraction__n_components": "np.arange(1, X[:, mask].shape[1])",
                        "estimator__n_estimators": "[100, 200, 250]",
                        "estimator__max_depth": "[10, 15]",
                        "estimator__max_features": "['sqrt', 'log2']"
                    }
                ],
                "metrics": [
                    "neg_root_mean_squared_error",
                    "r2",
                    "neg_mean_absolute_error"
                ],
                "n_split_outer_cv": 10,
                "n_split_inner_cv": 10
            }
        }
    }
}